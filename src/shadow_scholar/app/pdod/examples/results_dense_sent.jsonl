{"did": 2, "text": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale.", "label": null, "score": 1.2213674783706665, "qid": 1}
{"did": 2, "text": "Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.", "label": null, "score": 1.0399980545043945, "qid": 1}
{"did": 1, "text": "We test our agent's abilities in text games -- challenging benchmarks for evaluating the multi-step reasoning abilities of game agents in grounded, language-based environments.", "label": null, "score": 0.8719993829727173, "qid": 1}
{"did": 2, "text": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "label": null, "score": 0.8617950677871704, "qid": 1}
{"did": 2, "text": "They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.", "label": null, "score": 0.8515040874481201, "qid": 1}
{"did": 1, "text": "In this work, we explore techniques for augmenting interactive agents with information from symbolic modules, much like humans use tools like calculators and GPS systems to assist with arithmetic and navigation.", "label": null, "score": 0.8406718969345093, "qid": 1}
{"did": 2, "text": "In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.", "label": null, "score": 0.7998294830322266, "qid": 1}
{"did": 1, "text": "This action injection technique is easily extended to new agents, environments, and symbolic modules.", "label": null, "score": 0.7990187406539917, "qid": 1}
{"did": 1, "text": "Our experimental study indicates that injecting the actions from these symbolic modules into the action space of a behavior cloned transformer agent increases performance on four text game benchmarks that test arithmetic, navigation, sorting, and common sense reasoning by an average of 22%, allowing an agent to reach the highest possible performance on unseen games.", "label": null, "score": 0.7712363004684448, "qid": 1}
{"did": 2, "text": "This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "label": null, "score": 0.6848065853118896, "qid": 1}
{"did": 2, "text": "We incorporate a range of tools, including a calculator, a Q&A system, two different search engines, a translation system, and a calendar.", "label": null, "score": 0.6807278394699097, "qid": 1}
{"did": 2, "text": "We incorporate a range of tools, including a calculator, a Q&A system, two different search engines, a translation system, and a calendar.", "label": null, "score": 0.4033316671848297, "qid": 2}
{"did": 2, "text": "This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "label": null, "score": 0.3998309075832367, "qid": 2}
{"did": 2, "text": "They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.", "label": null, "score": 0.39789605140686035, "qid": 2}
{"did": 1, "text": "In this work, we explore techniques for augmenting interactive agents with information from symbolic modules, much like humans use tools like calculators and GPS systems to assist with arithmetic and navigation.", "label": null, "score": 0.39042699337005615, "qid": 2}
{"did": 1, "text": "Our experimental study indicates that injecting the actions from these symbolic modules into the action space of a behavior cloned transformer agent increases performance on four text game benchmarks that test arithmetic, navigation, sorting, and common sense reasoning by an average of 22%, allowing an agent to reach the highest possible performance on unseen games.", "label": null, "score": 0.3900143504142761, "qid": 2}
{"did": 1, "text": "This action injection technique is easily extended to new agents, environments, and symbolic modules.", "label": null, "score": 0.38884595036506653, "qid": 2}
{"did": 1, "text": "We test our agent's abilities in text games -- challenging benchmarks for evaluating the multi-step reasoning abilities of game agents in grounded, language-based environments.", "label": null, "score": 0.34997040033340454, "qid": 2}
{"did": 2, "text": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "label": null, "score": 0.34755635261535645, "qid": 2}
{"did": 2, "text": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale.", "label": null, "score": 0.3466978669166565, "qid": 2}
{"did": 2, "text": "In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.", "label": null, "score": 0.3331267535686493, "qid": 2}
{"did": 2, "text": "Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.", "label": null, "score": 0.32779455184936523, "qid": 2}
